\documentclass{article}
\title{ASL Pipeline}
\begin{document}

\maketitle

\section{Introduction}

ASL is important (see FNIH proposal)

We want to test a pipeline for ASL and CBF in neurodegeneration.

Technical details of ASL reconstruction are covered in the
following excellent papers:
\begin{itemize}
  \item Implementation of Quantitative Perfusion Imaging Techniques for Functional Brain Mapping using Pulsed Arterial Spin Labeling

\item Quantitative analysis of arterial spin labeling FMRI data using a general linear model

\item Improving cerebral blood flow quantification for arterial spin labeled
perfusion MRI by removing residual motion artifacts and global
signal fluctuations
\end{itemize}

\section{Methods and Reproducible Pipeline Example}

\subsection{Inputs and outputs}
Inputs for ASL reconstruction:
\begin{enumerate}
  \item ASL image
  \item T1 image, same subject as ASL
  \item T1 tissue segmentation and brain mask 
  \item Parameters for ASL sequence, otherwise defaults will be used,
    e.g. : Transit time ($\delta$)=1500 ms, inv. efficiency ($\alpha$)=0.85, gray matter T1=1400 ms, arterial T1=1600 ms .
  \item Other pipeline parameters (to be determined) such as spatial
    and temporal smoothing.
  \item Template with priors.
  \end{enumerate}
  
This workflow begins with raw ASL and T1 nifti images as input.  So, we need spatial priors such as cerebrum masks and tissue probabilities to guide the segmentation of both T1 and perfusion.  First, we show a simple (ok but not optimal) approach to brain extraction and segmentation.
  
  

\paragraph{Not yet implemented: quantitative cbf - ask jeff}
\paragraph{Not yet implemented: quantitative control - think about this}


First, we load in the input data.
<<load,results="hide">>=

suppressMessages(require(ANTsR))
opts_knit$set(progress = TRUE, verbose = TRUE)
rootdir<-"../data/"
data("aal", package="ANTsR")
aalimg        <- antsImageRead(paste(rootdir,"template/Labels/aal.nii.gz",sep=''), 3)
m0            <- antsImageRead(paste(rootdir,"M0.nii.gz",sep=''), 3)
pasl          <- antsImageRead(paste(rootdir,"PASL.nii.gz",sep=''), 4)
pcasl         <- antsImageRead(paste(rootdir,"PCASL.nii.gz",sep=''), 4)
pcasl         <- antsImageRead(paste(rootdir,"PEDS012_20100813_pcasl_1.nii.gz",sep=''), 4)
pcasl         <- antsImageRead(paste(rootdir,"109896_20100617_0005_ep2d_se_pcasl_PHC_1500ms.nii.gz",sep=''), 4)
casl          <- antsImageRead(paste(rootdir,"CASL.nii.gz",sep=''), 4)
t1            <- antsImageRead(paste(rootdir,"t1.nii.gz",sep=''), 3)
t1            <- antsImageRead(paste(rootdir,"PEDS012_20100813_mprage_t1.nii.gz",sep=''), 3)
t1            <- antsImageRead(paste(rootdir,"109896_20100617_mprage_t1.nii.gz",sep=''), 3)
template      <- antsImageRead(paste(rootdir,"template/T1template.nii.gz",sep=''), 3)
mask.cerebrum <- antsImageRead(paste(rootdir,"template/Labels/T1template_cerebrummask.nii.gz",sep=''), 3)
prior.csf     <- antsImageRead(paste(rootdir,"template/Labels/T1template_prior_01.nii.gz",sep=''), 3)
prior.gm      <- antsImageRead(paste(rootdir,"template/Labels/T1template_prior_02.nii.gz",sep=''), 3)
prior.wm      <- antsImageRead(paste(rootdir,"template/Labels/T1template_prior_03.nii.gz",sep=''), 3)

@

\subsection{Segmenting the individual T1 with a template and co-registration between ASL and T1}


Before we do any ASL processing, we have to do appropriate preprocessing (bias correction, brain extraction, and segmentation) of the T1 image. 

<<preprocessN4,results="hide">>=

outdir <- paste("./Z/", sep='')
dir.create(outdir)
t1.n4 <- abpN4(img=t1,  intensityTruncation=c( 0.025, 0.999, 256 ) )

@ 

Now the brain extraction 

<<preprocessBXT,results="hide">>=

t1.brainx <- abpBrainExtraction(img=t1, tem=template, temmask = mask.cerebrum , tdir = outdir )

@


Better segmentation and bias correction.

<<betterSegment,results="hide">>=

if ( TRUE ) {
# you can redo the registration if you want, using only the brain but for this example, 
# we can use the transforms computed by the brain extraction step
# transform.t12template <- suppressMessages(antsRegistration(
#  fixed=templatebrain, moving=t1.brainx$brain, "Affine", outdir))
prob1warped <- antsApplyTransforms( t1.brainx$brain, prior.csf, 
                      transformlist=t1.brainx$invtransforms )
prob2warped <- antsApplyTransforms( t1.brainx$brain, prior.gm, 
                      transformlist=t1.brainx$invtransforms )
prob3warped <- antsApplyTransforms( t1.brainx$brain, prior.wm, 
                      transformlist=t1.brainx$invtransforms )
probabilityimages<-list( prob1warped, prob2warped  ,  prob3warped )
# resegment with use of prior 
brain<-antsImageClone( t1.brainx$brain )
for ( its in 1:3 ) {
  segs <- Atropos(d = 3, a = brain, m = "[0.1,1x1x1]", c = "[25,0]",
    i = probabilityimages, x =  t1.brainx$bmask , priorweight = 0.25 )
  mywmask<-antsImageClone( t1.brainx$bmask )
  ImageMath(3,mywmask,"+",segs$probabilityimages[[2]],segs$probabilityimages[[3]])
  brain<-abpN4( img = t1.brainx$brain , intensityTruncation=c( 0.01, 0.999, 256 )  ,
        mask = t1.brainx$bmask , weightimg= mywmask  )
  ImageMath(3, brain,'m', brain, t1.brainx$bmask)
}
segs <- Atropos(d = 3, a = brain, m = "[0.1,1x1x1]", c = "[25,0]",
    i = probabilityimages, x =  t1.brainx$bmask , priorweight = 0.0 )
t1.brainx$kmeansseg<-segs$segmentation
}

@ 

Now, we get an affine registration from the M0 image to the T1 image and a deformable registration from the T1 image to the template so that we can use the template cerebrum mask, if desired. 

In the case of PCASL, we register to the average ASL image.

<<register,results="hide">>=

avgpcasl<-new( "antsImage" , "float" , 3 )
antsMotionCorr( list( d = 3 , a = pcasl , o = avgpcasl ) )
plotANTsImage( avgpcasl, slices="1x14x2",axis=0)
transform.asl2t1 <- suppressMessages(antsRegistration(t1.brainx$brain, avgpcasl, "Rigid", outdir ))
concatenatedtx<-c(  unlist( t1.brainx$fwdtransforms ) , unlist( transform.asl2t1$fwdtransforms ) )
pcasl.warped <- antsApplyTransforms( template, avgpcasl, 
                      transformlist=concatenatedtx )
par( mfrow=c(2,1))
plotANTsImage( template      , slices="60x120x10", axis=0 )
plotANTsImage( pcasl.warped  , slices="60x120x10", axis=0 )

# also get the t1 brain extraction mask into the space of the asl
pcaslmask<-new( "antsImage" , "float" , 3 )
antsApplyTransforms( list( d=3, i=t1.brainx$bmask,interpolator="NearestNeighbor",
  o=pcaslmask,r=avgpcasl,t=paste("[",transform.asl2t1$invtransforms[1],",1]",sep='') ) )
par( mfrow=c(2,1))
plotANTsImage( avgpcasl , slices="1x14x2",axis=0)
plotANTsImage( pcaslmask, slices="1x14x2",axis=0)

@

If the warped pcasl looks aligned with the template, then the brain extraction step and mapping between the average pcasl and t1 are ok.  The quality could be improved beyond this approach but this may be reasonable for many datasets.


\subsection{Estimating Perfusion from the ASL Time Series}

Given the inputs listed above, the pipeline will estimate perfusion from an ASL time series using a (robust) regression approach.  Several steps are required:
\begin{itemize}
  \item Motion  correction.
  \item Masking the ASL image, possibly by using the T1 mask and
    coregistration with T1.
  \item Find nuisance variables such as global signal (FIXME --- optional
    maybe we should change the code to make this explicit)
    and compcor summary of physiological confounds (FIXME should probably test
    compcor again or show its output in this doc)
    \item At this point, if doing network analysis, we would use one
      of the approaches described in \cite{Wong97,Weber2013}.   Sinc interpolation.
   \item Employ linear regression to estimate the mean perfusion itself
     while controlling for the nuisance variables.  (FIXME - how to
     set robustness parameter , noted briefly )
   \item Currently, the ANTsR function aslPerfusion will estimate the m0 image from
     the mean of the control tags assuming that the data is acquired T
     C T C as is most of JJ's data.   This is applicable for
     CASL/PCASL but PASL requires a separately acquired M0.  FIXME ---
     The function should support both operations maskThresh should be maskOption
     \item FIXME --- This function should also alternatively take a mask in from
       the user which defines where mean perfusion will be calculated (e.g. you
       dont want to compute it in background). 
   \end{itemize}
The output of these steps is the mean perfusion image adjusted for
the user-selected covariates.  All of the above steps are implemented in aslPerfusion in ANTsR. Once
complete, quantitative CBF can be obtained by mutiplying the output of
this function by sequence dependent constants that account for
labeling efficiency, slice timing and inversion efficiency .  
Note that there are additional corrections that can be made for
subject-specific effects on CBF (e.g. measurements of T1 relaxation
time in blood \cite{Varsha}) which we may implement in the future.  

After obtaining the requisite masks, we can compute perfusion and CBF from the raw ASL images.  All necessary steps, including motion correction, detrending, and regression of physiological confounds are done automatically.

<<computePerfusion,results="hide">>=

pcasl.processing <- aslPerfusion(pcasl, mask=pcaslmask,moreaccurate=FALSE )
# in above, we should truncate outliers or add a 2nd filter / function to do so
pcasl.perfusion <- pcasl.processing$perfusion

@

Now you can convert perfusion to CBF via standard quantification equations for your sequence.

<<quantCBF,results="hide">>=

pcasl.parameters <- list( sequence="pcasl", m0=pcasl.processing$m0 )
cbf <- quantifyCBF( pcasl.perfusion, pcaslmask, pcasl.parameters )
cbf.warped2template <- antsApplyTransforms( template, cbf$meancbf,
                        transformlist=concatenatedtx )
cbf.warped2t1 <- antsApplyTransforms( fixed=t1, moving=cbf$meancbf, transformlist=c(unlist(transform.asl2t1$fwdtransforms ) ))

@

\subsection{PVC}

Once we have perfusion in the subject space (or CBF), we may want to
estimate partial volume correction to assign the degree to which CBF
is determined by the underlying brain structure.  This can be a key to
separating structural and functional signatures of disease.


<<PVC,results="hide">>=

gm<-prob2warped
wm<-prob3warped
pcbf<-partialVolumeCorrection( cbf.warped2t1, gm, wm )
antsImageWrite(pcbf,'pcbf.nii.gz')

@ 

\subsection{Quality Control Measurements}

As a starter show histograms of the CBF image measurements in CSF, GM, WM


<<getAAL,results="hide">>=

aal2t1<-antsApplyTransforms( fixed=t1,moving=allimg,interpolator="NearestNeighbor",t=t1.brainx$invtransforms )
# transform this to the perfusion space and mask with the same mask
# used for cbf .... or subset the matrix with the appropriate aal labels
# then do some network biz
concatenatedtx<-c(  unlist( t1.brainx$invtransforms ),  unlist( transform.asl2t1$invtransforms ) )
aal2asl <- antsApplyTransforms( moving=allimg, fixed=avgpcasl, interpolator="NearestNeighbor",
                      t=concatenatedtx )

@

Now use these to look at cbf variation in different tissue.

<<qcCBF,results="hide">>=

  tmask<-antsImageClone(t1.brainx$kmeansseg)
  tmask[ t1.brainx$kmeansseg != 2 ]<-0
  tmask[ t1.brainx$kmeansseg == 2 ]<-1
  qcvaluesg<-getROIValues( cbf.warped2t1, aal2t1, tmask)
  tmask[ t1.brainx$kmeansseg != 3 ]<-0
  tmask[ t1.brainx$kmeansseg == 3 ]<-1
  tmaskf<-antsImageClone(tmask,"float")
  ImageMath(3,tmaskf,"ME",tmaskf,2)
  ImageMath(3,tmaskf,"GetLargestComponent",tmaskf)
  tmask<-antsImageClone(tmaskf,"unsigned int")
  qcvaluesw<-getROIValues( cbf.warped2t1, tmask, tmask)

@



<<meanCBF>>=

print(paste("Mean GM",mean( qcvaluesg$roiMeans ),"Mean WM",mean( qcvaluesw$roiMeans )))

@ 

plot the temporal SD image 

\subsection{Network analysis}

do a quick study of some common networks - salience, DMN, etc


<<cbfNetwork>>=

mask<-pcasl.processing$mask
filterpcasl<-getfMRInuisanceVariables( pcasl, mask = mask , moreaccurate=F )
tsResid<-residuals( lm( filterpcasl$matrixTimeSeries ~ filterpcasl$nuisancevariables + pcasl.processing$xideal ))
mynetwork<-filterfMRIforNetworkAnalysis( tsResid , tr=4, mask=mask ,cbfnetwork = "ASLCBF", labels = aal2asl , graphdensity = 0.05 )
plot( mynetwork$graph$walktrapcomm, mynetwork$graph$mygraph )

# look at dmn
data("aal", package="ANTsR")
mydmn<-which( aal$isdmn == 1 )
dmngraph1<-makeGraph( mynetwork$corrmat[ mydmn, mydmn ] , 0.25 )
mydmn2<-which( aal$isdmn >= 1 )
dmngraph2<-makeGraph( mynetwork$corrmat[ mydmn2, mydmn2 ] , 0.25 )


@

Write out results.

<<writeIt>>=

fn<-paste(outdir,'brain.nii.gz',sep='')
antsImageWrite( brain , fn )
fn<-paste(outdir,'seg.nii.gz',sep='')
antsImageWrite( segs$segmentation , fn )
for ( i in 1:3 ) {
  fn<-paste(outdir,'prob_0',i,'.nii.gz',sep='')
  antsImageWrite( segs$probabilityimages[[i]] , fn )
}
#
# write out asl data 
#
fn<-paste(outdir,'aal2asl.nii.gz',sep='')
antsImageWrite( aal2asl , fn ) 
fn<-paste(outdir,'asl_mask.nii.gz',sep='')
antsImageWrite( pcaslmask , fn ) 
myasldata <- data.frame( xideal = pcasl.processing$xideal , nuis = pcasl.processing$nuisancevariables )
fn<-paste(outdir,'asl_data.csv',sep='')
write.csv( myasldata, fn, quote=F, row.names=F )
fn<-paste(outdir,'asl_timeseries.mha',sep='')
antsImageWrite( as.antsImage( pcasl.processing$aslTimeSeries ) , fn )
fn<-paste(outdir,'networkCorr.mha',sep='')
antsImageWrite( as.antsImage(mynetwork$network) , fn )
fn<-paste(outdir,'m0.nii.gz',sep='')
antsImageWrite( pcasl.processing$m0 , fn ) 
#                                        
# cbf stuff
#
fn<-paste(outdir,'cbf.nii.gz',sep='')
antsImageWrite( cbf$meancbf , fn ) 


@ 

\subsection{Population Analysis}

Finally, mapping to a group template may be useful for voxel-wise
group studies or analysis by decomposition as we perform in eigenanatomy.

\section{Discussion}

We did it!

\end{document}
